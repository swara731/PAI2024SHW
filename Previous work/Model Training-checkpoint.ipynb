{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8591621-91d2-4e39-8a05-788e079df1c7",
   "metadata": {},
   "source": [
    "### Additional Data Preprocessing\n",
    "Although the data has been preprocessed in DataEngineer.ipynb, to continue the steps, this data might need additional preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26822183-6e12-4165-a3eb-faee95bc8ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary things\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd012f1b-c932-48f9-9412-fa361dd70067",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf2bef33-e90e-4561-84f8-b910accb664d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75 images belonging to 3 classes.\n",
      "Found 16 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "train_dir = 'data/train'\n",
    "val_dir = 'data/val'\n",
    "test_dir = 'data/test'\n",
    "input_shape = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow images from directories and apply data augmentation\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=input_shape,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=input_shape,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d61b53-2a35-4448-98dd-046b667811d1",
   "metadata": {},
   "source": [
    "### Define model architecture\n",
    "\n",
    "for ResNet50, DenseNet121, MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "717968a7-39f0-4826-930f-f84fcc4f2731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Summary:\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d_2  (None, 2048)              0         \n",
      " 7 (GlobalAveragePooling2D)                                      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 3)                 6147      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23593859 (90.00 MB)\n",
      "Trainable params: 23540739 (89.80 MB)\n",
      "Non-trainable params: 53120 (207.50 KB)\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 2 Summary:\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet121 (Functional)    (None, 4, 4, 1024)        7037504   \n",
      "                                                                 \n",
      " global_average_pooling2d_2  (None, 1024)              0         \n",
      " 8 (GlobalAveragePooling2D)                                      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 3)                 3075      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7040579 (26.86 MB)\n",
      "Trainable params: 6956931 (26.54 MB)\n",
      "Non-trainable params: 83648 (326.75 KB)\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 3 Summary:\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_128 (Func  (None, 4, 4, 1280)        2257984   \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " global_average_pooling2d_2  (None, 1280)              0         \n",
      " 9 (GlobalAveragePooling2D)                                      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 3)                 3843      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2261827 (8.63 MB)\n",
      "Trainable params: 2227715 (8.50 MB)\n",
      "Non-trainable params: 34112 (133.25 KB)\n",
      "_________________________________________________________________\n",
      "\n",
      "Found 75 images belonging to 3 classes.\n",
      "Found 16 images belonging to 3 classes.\n",
      "Found 18 images belonging to 3 classes.\n",
      "Training Model 1...\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7622 - accuracy: 0.6667 \n",
      "Epoch 1: val_loss improved from inf to 2.32048, saving model to model_checkpoints\\model_01-2.32.h5\n",
      "3/3 [==============================] - 88s 26s/step - loss: 0.7622 - accuracy: 0.6667 - val_loss: 2.3205 - val_accuracy: 0.4375\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1504 - accuracy: 0.9467 \n",
      "Epoch 2: val_loss did not improve from 2.32048\n",
      "3/3 [==============================] - 39s 17s/step - loss: 0.1504 - accuracy: 0.9467 - val_loss: 16.9173 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1933 - accuracy: 0.9200 \n",
      "Epoch 3: val_loss did not improve from 2.32048\n",
      "3/3 [==============================] - 40s 12s/step - loss: 0.1933 - accuracy: 0.9200 - val_loss: 60.9787 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0649 - accuracy: 0.9600 \n",
      "Epoch 4: val_loss did not improve from 2.32048\n",
      "3/3 [==============================] - 39s 16s/step - loss: 0.0649 - accuracy: 0.9600 - val_loss: 215.0295 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9600 \n",
      "Epoch 5: val_loss did not improve from 2.32048\n",
      "3/3 [==============================] - 42s 12s/step - loss: 0.0668 - accuracy: 0.9600 - val_loss: 62.7272 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1898 - accuracy: 0.9467\n",
      "Epoch 6: val_loss did not improve from 2.32048\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "3/3 [==============================] - 41s 12s/step - loss: 0.1898 - accuracy: 0.9467 - val_loss: 23.1185 - val_accuracy: 0.3125\n",
      "Epoch 6: early stopping\n",
      "Training duration for Model 1: 290.33 seconds\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.3506 - accuracy: 0.3889\n",
      "Test Loss: 2.3506\n",
      "Test Accuracy: 0.3889\n",
      "\n",
      "Training Model 2...\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.1098 - accuracy: 0.6533\n",
      "Epoch 1: val_loss improved from 2.32048 to 0.64843, saving model to model_checkpoints\\model_01-0.65.h5\n",
      "3/3 [==============================] - 131s 21s/step - loss: 1.1098 - accuracy: 0.6533 - val_loss: 0.6484 - val_accuracy: 0.7500\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2294 - accuracy: 0.9600\n",
      "Epoch 2: val_loss did not improve from 0.64843\n",
      "3/3 [==============================] - 40s 13s/step - loss: 0.2294 - accuracy: 0.9600 - val_loss: 3.2007 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1364 - accuracy: 0.9867\n",
      "Epoch 3: val_loss did not improve from 0.64843\n",
      "3/3 [==============================] - 42s 13s/step - loss: 0.1364 - accuracy: 0.9867 - val_loss: 4.5225 - val_accuracy: 0.5625\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3061 - accuracy: 0.9333 \n",
      "Epoch 4: val_loss did not improve from 0.64843\n",
      "3/3 [==============================] - 39s 17s/step - loss: 0.3061 - accuracy: 0.9333 - val_loss: 4.3761 - val_accuracy: 0.5625\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1226 - accuracy: 0.9600 \n",
      "Epoch 5: val_loss did not improve from 0.64843\n",
      "3/3 [==============================] - 38s 11s/step - loss: 0.1226 - accuracy: 0.9600 - val_loss: 6.2545 - val_accuracy: 0.4375\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9333 \n",
      "Epoch 6: val_loss did not improve from 0.64843\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "3/3 [==============================] - 41s 17s/step - loss: 0.0917 - accuracy: 0.9333 - val_loss: 7.4770 - val_accuracy: 0.3125\n",
      "Epoch 6: early stopping\n",
      "Training duration for Model 2: 373.17 seconds\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4121 - accuracy: 0.7778\n",
      "Test Loss: 0.4121\n",
      "Test Accuracy: 0.7778\n",
      "\n",
      "Training Model 3...\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7719 - accuracy: 0.6133\n",
      "Epoch 1: val_loss did not improve from 0.64843\n",
      "3/3 [==============================] - 39s 5s/step - loss: 0.7719 - accuracy: 0.6133 - val_loss: 1.3047 - val_accuracy: 0.7500\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1396 - accuracy: 0.9333\n",
      "Epoch 2: val_loss did not improve from 0.64843\n",
      "3/3 [==============================] - 12s 4s/step - loss: 0.1396 - accuracy: 0.9333 - val_loss: 1.0707 - val_accuracy: 0.6250\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3201 - accuracy: 0.9200\n",
      "Epoch 3: val_loss did not improve from 0.64843\n",
      "3/3 [==============================] - 12s 3s/step - loss: 0.3201 - accuracy: 0.9200 - val_loss: 1.8001 - val_accuracy: 0.5625\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2349 - accuracy: 0.9333\n",
      "Epoch 4: val_loss did not improve from 0.64843\n",
      "3/3 [==============================] - 11s 3s/step - loss: 0.2349 - accuracy: 0.9333 - val_loss: 3.6964 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3731 - accuracy: 0.9467\n",
      "Epoch 5: val_loss did not improve from 0.64843\n",
      "3/3 [==============================] - 14s 4s/step - loss: 0.3731 - accuracy: 0.9467 - val_loss: 6.3234 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.9733\n",
      "Epoch 6: val_loss did not improve from 0.64843\n",
      "3/3 [==============================] - 15s 6s/step - loss: 0.1235 - accuracy: 0.9733 - val_loss: 14.3227 - val_accuracy: 0.3750\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1055 - accuracy: 0.9600\n",
      "Epoch 7: val_loss did not improve from 0.64843\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "3/3 [==============================] - 12s 4s/step - loss: 0.1055 - accuracy: 0.9600 - val_loss: 21.6760 - val_accuracy: 0.3125\n",
      "Epoch 7: early stopping\n",
      "Training duration for Model 3: 115.74 seconds\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 2.4248 - accuracy: 0.5556\n",
      "Test Loss: 2.4248\n",
      "Test Accuracy: 0.5556\n",
      "\n",
      "Training and evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50, DenseNet121, MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "\n",
    "# Define number of classes\n",
    "num_classes = 3\n",
    "\n",
    "# Load pre-trained models without top layers\n",
    "base_models = [\n",
    "    ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3)),\n",
    "    DenseNet121(weights='imagenet', include_top=False, input_shape=(128, 128, 3)),\n",
    "    MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "]\n",
    "\n",
    "# Model Building\n",
    "# Build custom models on top of each base model\n",
    "models = []\n",
    "for base_model in base_models:\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    models.append(model)\n",
    "\n",
    "# Model compilation\n",
    "# Compile the models\n",
    "for model in models:\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Print model summaries\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Model {i+1} Summary:\")\n",
    "    model.summary()\n",
    "    print()\n",
    "\n",
    "# Setting up Data Generators\n",
    "train_dir = 'data/train'\n",
    "val_dir = 'data/val'\n",
    "test_dir = 'data/test'\n",
    "\n",
    "batch_size = 32\n",
    "target_size = (128, 128)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Define callbacks to prevent overfitting etc\n",
    "checkpoint_path = 'model_checkpoints/model_{epoch:02d}-{val_loss:.2f}.h5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min', restore_best_weights=True)\n",
    "\n",
    "# Training loop\n",
    "for model in models:\n",
    "    print(f\"Training Model {models.index(model) + 1}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=30,  # Adjusted to 30 epochs\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[checkpoint, early_stopping]\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    training_duration = end_time - start_time\n",
    "    print(f\"Training duration for Model {models.index(model) + 1}: {training_duration:.2f} seconds\")\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    loss, accuracy = model.evaluate(test_generator)\n",
    "    print(f\"Test Loss: {loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "  \n",
    "\n",
    "    print()\n",
    "\n",
    "# Print final conclusions or comparisons based on metrics and training times\n",
    "print(\"Training and evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2161b4e9-124a-4a3f-b1b1-854bc9d93168",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "using grid search or randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acdc5d20-2e28-469e-b87d-6065704e7b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (2.13.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.13.1-cp38-cp38-win_amd64.whl.metadata (2.6 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (7.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dea8a1fa-6173-4283-b34d-43a0bebafe6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\hp\\anaconda3\\envs\\isb46703\\lib\\site-packages (2.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac8fbf4-e76c-409e-a3b5-3dc65e74f1d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ResNet50\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasClassifier\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Define number of classes and input shape\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.wrappers'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define number of classes and input shape\n",
    "num_classes = 3\n",
    "input_shape = (128, 128, 3)\n",
    "\n",
    "# Function to build model with specific hyperparameters\n",
    "def build_model(learning_rate=0.001, batch_size=32):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'batch_size': [16, 32, 64]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=KerasClassifier(build_fn=build_model, epochs=30, verbose=0),\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=3)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(train_generator, validation_data=val_generator)\n",
    "\n",
    "# Print best parameters and results\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128b42be-a1a8-4eef-92f6-987ed31d453a",
   "metadata": {},
   "source": [
    "cannot proceed to perform hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54bbc8c-1b33-49ac-bcad-e7f8437898c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
