{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f2d2f32-85a0-4fc1-a126-4a97f6b9ccca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\nuryn\\anaconda3\\envs\\isb46703\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\nuryn\\anaconda3\\envs\\isb46703\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\nuryn\\anaconda3\\envs\\isb46703\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\nuryn\\anaconda3\\envs\\isb46703\\lib\\site-packages (4.10.0.82)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nuryn\\anaconda3\\envs\\isb46703\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nuryn\\anaconda3\\envs\\isb46703\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nuryn\\anaconda3\\envs\\isb46703\\lib\\site-packages (from requests) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nuryn\\anaconda3\\envs\\isb46703\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\nuryn\\anaconda3\\envs\\isb46703\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nuryn\\anaconda3\\envs\\isb46703\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nuryn\\anaconda3\\envs\\isb46703\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\nuryn\\anaconda3\\envs\\isb46703\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\nuryn\\anaconda3\\envs\\isb46703\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nuryn\\anaconda3\\envs\\isb46703\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Could not download https://www.pentaxforums.com/gallery/images/3123/1_IMGP7088_Thinned_2.jpg: HTTPSConnectionPool(host='www.pentaxforums.com', port=443): Max retries exceeded with url: /gallery/images/3123/1_IMGP7088_Thinned_2.jpg (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001AD1541BBB0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "Image downloading complete.\n",
      "Image standardization complete.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install requests beautifulsoup4 pandas opencv-python\n",
    "\n",
    "# Import required libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Function to get image URLs from a search URL\n",
    "def get_image_urls(search_url, max_images=50):\n",
    "    # Send a GET request to the search URL\n",
    "    response = requests.get(search_url)\n",
    "    # Parse the HTML content of the response\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # Find all 'a' tags with class 'iusc' (these contain image data)\n",
    "    image_elements = soup.find_all('a', class_='iusc')\n",
    "    \n",
    "    urls = []\n",
    "    # Iterate through the found image elements, up to the specified max_images\n",
    "    for img in image_elements[:max_images]:\n",
    "        # Get the 'm' attribute (contains image URL info)\n",
    "        m = img.get('m')\n",
    "        if m:\n",
    "            # Convert the string representation of a dictionary to an actual dictionary\n",
    "            m = eval(m)\n",
    "            if 'murl' in m:\n",
    "                # Append the image URL to the list\n",
    "                urls.append(m['murl'])\n",
    "    \n",
    "    # Return the list of image URLs\n",
    "    return urls\n",
    "\n",
    "# Function to download images from a list of URLs\n",
    "def download_images(urls, folder_name):\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    \n",
    "    # Iterate over the list of URLs\n",
    "    for i, url in enumerate(urls):\n",
    "        try:\n",
    "            # Get the content of the image URL\n",
    "            img_data = requests.get(url).content\n",
    "            # Save the image data to a file\n",
    "            with open(f'{folder_name}/{i+1}.jpg', 'wb') as handler:\n",
    "                handler.write(img_data)\n",
    "        except Exception as e:\n",
    "            # Print an error message if the image can't be downloaded\n",
    "            print(f\"Could not download {url}: {e}\")\n",
    "\n",
    "# Define search URLs for different cat breeds\n",
    "urls = {\n",
    "    'Maine Coon': 'https://www.bing.com/images/search?q=maine+coon+cat+images&form=HDRSC4&first=1',\n",
    "    'Persian': 'https://www.bing.com/images/search?q=persian+cat+images&form=HDRSC4&first=1',\n",
    "    'Siamese': 'https://www.bing.com/images/search?q=siamese+cat+images&FORM=HDRSC4'\n",
    "}\n",
    "\n",
    "# Fetch and download images for each cat breed\n",
    "for cat, url in urls.items():\n",
    "    # Get image URLs for the specified breed\n",
    "    image_urls = get_image_urls(url, max_images=50)  # You can increase max_images if needed\n",
    "    # Download images for the specified breed\n",
    "    download_images(image_urls, cat)\n",
    "\n",
    "print(\"Image downloading complete.\")\n",
    "\n",
    "#Standardize Data\n",
    "# Function to resize images to a standard size\n",
    "def resize_images(input_folder, output_folder, size=(128, 128)):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Iterate over the files in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        # Read the image\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            try:\n",
    "                # Resize the image to the specified size\n",
    "                resized_img = cv2.resize(img, size)\n",
    "                # Save the resized image to the output folder\n",
    "                cv2.imwrite(os.path.join(output_folder, filename), resized_img)\n",
    "            except Exception as e:\n",
    "                # Print an error message if the image can't be resized\n",
    "                print(f\"Could not resize {img_path}: {e}\")\n",
    "\n",
    "# Resize images for each cat breed\n",
    "for cat in urls.keys():\n",
    "    resize_images(cat, f'resized_{cat}') #creating dataset\n",
    "\n",
    "print(\"Image standardization complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50432f8f-5409-4056-9e71-a5a9dc1b8f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
